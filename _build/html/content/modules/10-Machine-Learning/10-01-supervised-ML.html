
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Machine Learning Basics &#8212; Data Chemistry 2025</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/oldcustom.css?v=e52fa269" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ba2d5b83" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/modules/10-Machine-Learning/10-01-supervised-ML';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Appendices" href="../../appendices/README.html" />
    <link rel="prev" title="Module 10: Supervised ML" href="README.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Data Chemistry 2025 - Home"/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt="Data Chemistry 2025 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    2025 Data Chemistry OLCC
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../01-OLCC-Primer/README.html">Module 1: OLCC Primer</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../01-OLCC-Primer/01-1-OLCC-Primer.html">1.1 OLCC Primer</a></li>





<li class="toctree-l2"><a class="reference internal" href="../01-OLCC-Primer/01-2-python-basics.html">1.2 Python Basics</a></li>


<li class="toctree-l2"><a class="reference internal" href="../01-OLCC-Primer/01-3-python-intermediate.html">1.3 Python Intermediate</a></li>





</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../02-Introduction/README.html">Module 2: Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../02-Introduction/02-1-PubChemDataTypes.html">PubChem Training Course</a></li>


<li class="toctree-l2"><a class="reference internal" href="../02-Introduction/02-2-PUG-REST-activity.html">Getting Molecular Properties through PubChem’s PUG REST Web Interface</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../03-Public-Chemical-Databases/README.html">Module 3: Public Chemical Databases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../03-Public-Chemical-Databases/03-01-Survey-Public-Chemical-Databases.html">Public Compound Databases</a></li>


</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../04-Chemical-Representations/README.html">Module 4: Chemical Representations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../04-Chemical-Representations/04-01-introduction_chemical_representations.html">Chemical Representations and Introduction to RDKit</a></li>

<li class="toctree-l2"><a class="reference internal" href="../04-Chemical-Representations/04-02-PubChem3D_update.html">PubChem3D</a></li>

<li class="toctree-l2"><a class="reference internal" href="../04-Chemical-Representations/04-03-Substructure_Searching_with_SMARTS.html">Substructure Searching with SMARTS</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../05-Searching-Chemical-Databases/README.html">Module 5: Searching Chemical Databases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../05-Searching-Chemical-Databases/05-01-Exploring-PubChem.html">Exploring PubChem</a></li>



<li class="toctree-l2"><a class="reference internal" href="../05-Searching-Chemical-Databases/05-02-structure-inputs.html">Chemical Structure Inputs for PUG-REST</a></li>
<li class="toctree-l2"><a class="reference internal" href="../05-Searching-Chemical-Databases/05-03-list-conversion.html">Intercoversion between PubChem records.</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../06-BioAssay/README.html">Module 6: BioAssays</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../06-BioAssay/06-1-Bioactivity_Primer.html">PubChem Bioactivity Primer</a></li>

<li class="toctree-l2"><a class="reference internal" href="../06-BioAssay/06-2-eda-protein1.html">Exploratory Data Analysis 1: <br/><br/> Concordance of Thyroid Hormone Receptor Activity in Rats and Humans</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06-BioAssay/06-3-eda-pathway.html">Exploratory Data Analysis 2:<br/><br/>Chemical Modulation of Renin-Angiotensin-Aldosterone system (RAAS)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../07-QSAR-QSPR/README.html">Module 7: Quantitative Structure Property Reationships</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../07-QSAR-QSPR/07-01-QSPR.html">Molecular Descriptors</a></li>








</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../08-Molecular-Similarity/README.html">Module 8: Molecular Similarity</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../08-Molecular-Similarity/08-1-MolSimularity.html">Fingerprint Generation</a></li>



<li class="toctree-l2"><a class="reference internal" href="../08-Molecular-Similarity/08-2-MolSimularity.html">What is a bit vector?</a></li>


<li class="toctree-l2"><a class="reference internal" href="../08-Molecular-Similarity/08-3-MolSimularity.html">Objectives</a></li>





</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../09-CADDD/README.html">Module 9: Computer-Aided Drug Discovery and Design</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../09-CADDD/09-1-virtual-screening.html">Virtual Screening</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="README.html">Module 10: Supervised ML</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Machine Learning Basics</a></li>





</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../appendices/README.html">Appendices</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../appendices/Pandas.html">Introduction to Pandas</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/DivCHED-CCCE/DataChemistry2025OLCC/master?urlpath=lab/tree/docs/content/modules/10-Machine-Learning/10-01-supervised-ML.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://nanohub.org/tools/datachemolcc/hub/user-redirect/git-pull?repo=https%3A//github.com/DivCHED-CCCE/DataChemistry2025OLCC&urlpath=lab/tree/DataChemistry2025OLCC/docs/content/modules/10-Machine-Learning/10-01-supervised-ML.ipynb&branch=master" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on JupyterHub"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="JupyterHub logo" src="../../../_static/images/logo_jupyterhub.svg">
  </span>
<span class="btn__text-container">JupyterHub</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/DivCHED-CCCE/DataChemistry2025OLCC/blob/master/docs/content/modules/10-Machine-Learning/10-01-supervised-ML.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/DivCHED-CCCE/DataChemistry2025OLCC" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DivCHED-CCCE/DataChemistry2025OLCC/issues/new?title=Issue%20on%20page%20%2Fcontent/modules/10-Machine-Learning/10-01-supervised-ML.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/content/modules/10-Machine-Learning/10-01-supervised-ML.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Machine Learning Basics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Machine Learning Basics</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-obtaining-and-cleaning-data">Part 1: Obtaining and Cleaning Data</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-bioactivity-data-from-pubchem">1. Import bioactivity data from PubChem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-the-number-of-compounds-for-each-activity-group">2. Check the number of compounds for each activity group</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#select-active-inactive-compounds-for-model-building">3. Select active/inactive compounds for model building</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-drop-substances-without-associated-cids">3a. Drop substances without associated CIDs.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-remove-cids-with-conflicting-activities">3b. Remove CIDs with conflicting activities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-remove-redundant-data">3c. Remove redundant data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-adding-numeric-activity-classes">3d. Adding “numeric” activity classes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#e-create-a-smaller-data-frame-that-only-contains-cids-and-activities">3e. Create a smaller data frame that only contains CIDs and activities.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#download-structure-information-for-each-compound-from-pubchem">4. Download structure information for each compound from PubChem</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-convert-smiles-to-binary-data-for-model-input">Part 2: Convert SMILES to Binary Data for Model Input</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-maccs-keys-from-smiles">5. Generate MACCS keys from SMILES.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#merge-activity-data-and-fingerprint-information">6. Merge activity data and fingerprint information</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-machine-learning">Part 3: Machine Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparation-for-model-building">7. Preparation for model building</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-loading-the-data-into-x-and-y">7a. Loading the data into X and y.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-remove-zero-variance-features">7b. Remove zero-variance features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-train-test-split-a-9-1-ratio">7c. Train-Test-Split (a 9:1 ratio)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-balancing-the-training-set">7d. Balancing the training set</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#downsampling">Downsampling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-a-model-using-the-training-set">8. Build a model using the training set.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-naive-bayes">8a. Naïve Bayes</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-decision-tree">8b Decision Tree</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-building-through-cross-validation">9. Model building through cross-validation</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#homework"><center>Homework</center></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-random-forest-with-ecfp4-descriptors">Part 1: Random Forest with ECFP4 descriptors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-model-comparison-and-prediction-evaluation">Part 2: Model Comparison and Prediction Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3">Part 3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#acknowledgments">Acknowledgments</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="machine-learning-basics">
<h1>Machine Learning Basics<a class="headerlink" href="#machine-learning-basics" title="Link to this heading">#</a></h1>
<p>Machine learning (ML) is a branch of artificial intelligence that enables computers to identify patterns and make predictions from data with minimal human intervention. In drug discovery, ML algorithms can analyze vast datasets of chemical structures, biological activities, and pharmacokinetic properties to predict which compounds are likely to be effective drugs. Applications include virtual screening of compound libraries, prediction of drug-target interactions, identification of potential toxicity, and optimization of lead compounds through structure-activity relationship (SAR) modeling. By accelerating these processes, ML helps reduce the time and cost associated with bringing new drugs to market.</p>
<p>In this notebook you will build binary classification models that predict activity/inactivity of small molecules against human aromatase using supervised learning methods, and evaluate the performance of the developed models using performance measures.</p>
<div class="alert alert-block alert-info">
<h2>Learning Objectives</h2>
<ul class="simple">
<li><p>Identify and address data quality issues to prepare chemical and biological data for machine learning.</p></li>
<li><p>Build and interpret binary classification models for prediction of activities at a target</p>
<ul>
<li><p>Naïve Bayes</p></li>
<li><p>Decision tree</p></li>
<li><p>Random forest</p></li>
</ul>
</li>
<li><p>Explore the Scikit-learn open-source machine learning Python library</p></li>
<li><p>Develop further Pandas skills to clean downloaded data</p></li>
<li><p>Review PubChem’s PUG REST Web Interface</p></li>
<li><p>Practice code from previous notebooks</p></li>
</ul>
<p><strong>Reading links</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.ibm.com/think/topics/naive-bayes">What are Naïve Bayes classifiers?</a></p></li>
<li><p><a class="reference external" href="https://www.ibm.com/think/topics/decision-trees">What is a decision tree?</a></p>
<ul>
<li><p><a class="reference external" href="https://www.ibm.com/think/topics/hyperparameter-tuning">What is hyperparameter tuning?</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.ibm.com/think/topics/random-forest">What is random forest?</a></p></li>
</ul>
<div class="alert alert-block alert-info">
</section>
<section class="tex2jax_ignore mathjax_ignore" id="part-1-obtaining-and-cleaning-data">
<h1>Part 1: Obtaining and Cleaning Data<a class="headerlink" href="#part-1-obtaining-and-cleaning-data" title="Link to this heading">#</a></h1>
<section id="import-bioactivity-data-from-pubchem">
<h2>1. Import bioactivity data from PubChem<a class="headerlink" href="#import-bioactivity-data-from-pubchem" title="Link to this heading">#</a></h2>
<p>In this notebook, we will develop a prediction model for small molecule’s activity against human aromatase (https://pubchem.ncbi.nlm.nih.gov/protein/EAW77416), which is encoded by the CYP19A1 gene (https://pubchem.ncbi.nlm.nih.gov/gene/1588). The model will predict the activity of a molecule based on the structure of the molecule (represented with molecular fingerprints).</p>
<p>Endocrine disrupting chemicals (EDCs) interfere with the biosynthesis and normal functions of steroid hormones including estrogen and androgen in the body. Aromatase catalyzes the conversion of androgen to estrogen and plays a key role in maintaining the androgen and estrogen balance in many of the EDC-sensitive organs.</p>
<p>For model development, we will use the Tox21 bioassay data for human aromatase, archived in PubChem (https://pubchem.ncbi.nlm.nih.gov/bioassay/743139).  The bioactivity data presented on this page can be downloaded by clicking the “Download” button available on this page and then read the data into a data frame.  Alternatively, you can directly load the data into a data frame as shown in the cell below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://pubchem.ncbi.nlm.nih.gov/assay/pcget.cgi?query=download&amp;record_type=datatable&amp;actvty=all&amp;response_type=save&amp;aid=743139&#39;</span>
<span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_raw</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>  <span class="c1"># gives the first 7 rows of the dataframe</span>
<span class="c1">#df_raw.tail(7) # gives the last 7 rows of the dataframe</span>
</pre></div>
</div>
</div>
</div>
<p>Data cleaning is a critical step in our workflow that ensures the quality, consistency, and reliability of a dataset before we build a model. Raw data often contains missing values, duplicates, inconsistent formatting, or mislabeled entries that can lead to incorrect conclusions or poorly performing models. By identifying and resolving these issues at the start of our model design, we create a dataset that accurately reflects the information needed for meaningful interpretation and predictive modeling.</p>
<p>Looking at our imported data, lines 0-2 provide the descriptions for each column (data type, descriptions, units, etc).  These rows need be removed. We will do so with a <strong>slice operation</strong> to select only those rows that contain the data we will use in the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_raw</span> <span class="o">=</span> <span class="n">df_raw</span><span class="p">[</span><span class="mi">3</span><span class="p">:]</span>  <span class="c1">#the [3:] indicates a slice opperation in pandas dataframes. It selects all rows starting</span>
                     <span class="c1">#at position 3 and continues to the end.</span>
<span class="n">df_raw</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The column names in this data frame contain white spaces and special characters.  For simplicity, let’s rename the columns (no spaces or special characters except for the “_” character.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_raw</span><span class="o">.</span><span class="n">columns</span> <span class="c1">#print out the column names. </span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">col_names_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;PUBCHEM_RESULT_TAG&#39;</span> <span class="p">:</span> <span class="s1">&#39;pc_result_tag&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;PUBCHEM_SID&#39;</span> <span class="p">:</span> <span class="s1">&#39;sid&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;PUBCHEM_CID&#39;</span> <span class="p">:</span> <span class="s1">&#39;cid&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;PUBCHEM_ACTIVITY_OUTCOME&#39;</span> <span class="p">:</span> <span class="s1">&#39;activity_outcome&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;PUBCHEM_ACTIVITY_SCORE&#39;</span> <span class="p">:</span> <span class="s1">&#39;activity_score&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;PUBCHEM_ACTIVITY_URL&#39;</span> <span class="p">:</span> <span class="s1">&#39;activity_url&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;PUBCHEM_ASSAYDATA_COMMENT&#39;</span> <span class="p">:</span> <span class="s1">&#39;assay_data_comment&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;Activity Summary&#39;</span> <span class="p">:</span> <span class="s1">&#39;activity_summary&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;Antagonist Activity&#39;</span> <span class="p">:</span> <span class="s1">&#39;antagonist_activity&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;Antagonist Potency (uM)&#39;</span> <span class="p">:</span> <span class="s1">&#39;antagonist_potency&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;Antagonist Efficacy (%)&#39;</span> <span class="p">:</span> <span class="s1">&#39;antagonist_efficacy&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;Viability Activity&#39;</span> <span class="p">:</span> <span class="s1">&#39;viability_activity&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;Viability Potency (uM)&#39;</span> <span class="p">:</span> <span class="s1">&#39;viability_potency&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;Viability Efficacy (%)&#39;</span> <span class="p">:</span> <span class="s1">&#39;viability_efficacy&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;Sample Source&#39;</span> <span class="p">:</span> <span class="s1">&#39;sample_source&#39;</span> <span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_raw</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="n">col_names_map</span><span class="p">)</span>
<span class="n">df_raw</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Check your understanding</strong>
<ol class="arabic simple">
<li><p>Why is it important to rename the column names without spaces or special characters?</p></li>
<li><p>In the code cell below, display the first 10 rows of the dataframe to indicate that the column names have been remapped.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your code here</span>
<span class="n">df_raw</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="check-the-number-of-compounds-for-each-activity-group">
<h2>2. Check the number of compounds for each activity group<a class="headerlink" href="#check-the-number-of-compounds-for-each-activity-group" title="Link to this heading">#</a></h2>
<p>First, we need to understand the structure of our data, particularly the activity class of the tested compounds, since our goal is to develop a model that classifies small molecules based on their activity against a target. This information is found in the <strong>activity_outcome</strong> and <strong>activity_summary</strong> columns of the dataframe.</p>
<p>To explore this, we use the <code class="docutils literal notranslate"><span class="pre">groupby</span></code> method, which splits the data into groups based on one or more column values, enabling us to perform calculations on each group independently. In the code cell below, we group by <strong>activity_outcome</strong> and use the <code class="docutils literal notranslate"><span class="pre">count</span></code> method to determine how many entries fall into each outcome category:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;activity_outcome&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Check your understanding</strong>
<ol class="arabic simple">
<li><p>How many actives, inactives and inconclusives compounds are there in the dataset based on the <strong>activity_outcome</strong> column?</p></li>
<li><p>Scroll through the rest of the data. Compare these numbers to other columns such as CID and SMILES. What problems might arise if these counts are not consistent?</p></li>
</ol>
<p>If we group by both <strong>activity_outcome</strong> and <strong>activity_summary</strong> we get more insight about the data. Particularly, it reveals information that will indicate that there are subcategories for “<strong>Inconclusive</strong>”, giving us a better understanding of how thse results are classified.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;activity_outcome&#39;</span><span class="p">,</span><span class="s1">&#39;activity_summary&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;there are&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_raw</span><span class="p">),</span><span class="s1">&#39;compounds in the dataframe that are defined as active antagonist, inactive, or inconclusive.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we can see that, in the <strong>activity_summary</strong> column, the inconclusive compounds are further classified into subclasses, which include:</p>
<ul class="simple">
<li><p><strong>active agonist</strong></p></li>
<li><p>inconclusive</p></li>
<li><p>inconclusive agonist</p></li>
<li><p>inconclusive antagonist</p></li>
<li><p>inconclusive agonist (cytotoxic)</p></li>
<li><p>inconclusive antagonist (cytotoxic)</p></li>
</ul>
<p>As implied in the title of this <a class="reference external" href="https://pubchem.ncbi.nlm.nih.gov/bioassay/743139">PubChem assay record (AID 743139)</a>, the goal of this assay is to identify <strong>aromatase inhibitors</strong>. Accordingly, all compounds labeled as active antagonists in the <strong>activity_summary</strong> column were marked as active in the <strong>activity_outcome</strong> column.</p>
<p>However, the assay also identified 612 <strong>active agonists</strong>, which are labeled as inconclusive in the <strong>activity_outcome</strong> column. This reflects the original submitter’s specific classification criteria: only antagonists were considered <strong>“active”</strong> for the purposes of identifying inhibitors.</p>
<p>In this context, <strong>inactive</strong> compounds are those that show neither agonist nor antagonist activity.</p>
<p>It’s important to recognize that the definitions of <strong>“active”</strong> and <strong>“inactive”</strong> depend on how the assay was designed and how its results were interpreted by the data submitter. For the purpose of this assignment (which aims to build a binary classifier to predict whether a compound is active or inactive) we will redefine these labels for consistency:</p>
<ul class="simple">
<li><p><strong>Active</strong>: Any compound that alters the activity of the target, either by increasing (agonist) or decreasing (antagonist) its function. This includes all compounds labeled as <strong>active antagonists</strong> or <strong>active agonists</strong> in the <strong>activity_summary</strong> column.</p></li>
<li><p><strong>Inactive</strong>: Compounds that do not change the activity of the target, corresponding to those labeled inactive in the <strong>activity_summary</strong> column.</p></li>
</ul>
<p>In short, we are treating <em><u>any molecule</u></em> that interacts with the enzyme as <strong>active</strong>, and those that do not as <strong>inactive</strong>. This operational definition is critical for building a model that accurately classifies compound-target interactions.</p>
<div class="alert alert-block alert-warning">
<strong>Check your understanding</strong>
<p>Imagine we build our model using only compounds labeled as active antagonists as the “active” class. What might be the consequences of this decision for the type of model we create? Could this be useful in some cases? What would it miss?</p>
</section>
<section id="select-active-inactive-compounds-for-model-building">
<h2>3. Select active/inactive compounds for model building<a class="headerlink" href="#select-active-inactive-compounds-for-model-building" title="Link to this heading">#</a></h2>
<p>Now we want to select only the active and inactive compounds from the data frame (that is, active agonists, active antagonists, and inactives based on the “activity summary” column).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create a new dataframe with active agonists, active antagnonists and inactives</span>
<span class="c1"># remove any molecules that are inconclusive</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df_raw</span><span class="p">[</span> <span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;activity_summary&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;active agonist&#39;</span> <span class="p">)</span> <span class="o">|</span> 
             <span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;activity_summary&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;active antagonist&#39;</span> <span class="p">)</span> <span class="o">|</span>
             <span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;activity_summary&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;inactive&#39;</span> <span class="p">)</span> <span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of total molecules that are active or inactive is:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Since we will be obtaining structural data from PubChem, it’s important to examine how many unique PubChem Substance IDs (SIDs) and Compound IDs (CIDs) are present in our dataset.</p>
<p>Recall the distinction:</p>
<ul class="simple">
<li><p><strong>Substances (SIDs)</strong> represent depositor-submitted records. Multiple SIDs may refer to the same chemical structure if submitted by different sources.</p></li>
<li><p><strong>Compounds (CIDs)</strong> are standardized, unique chemical structures derived by PubChem from submitted substances through a process of structure normalization and deduplication.</p></li>
</ul>
<p>Understanding how many unique SIDs and CIDs we have will help us assess redundancy and ensure we’re working with non-duplicated chemical structures when building models or visualizing data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># identify Compounds IDs and Substance IDs. </span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of unique Substance IDs=&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;sid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of unique Compound IDs= &#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<p>This data indicates two important points:</p>
<p>1)The number of unique Substance IDs matches the number of active and inactive molecules in the dataset.</p>
<p>2)Not all substances have an associated Compound ID (CID), meaning some structures have not been standardized by PubChem.</p>
<p>Since our goal is to build a model that uses chemical structure to predict biological activity, we must remove substances without CIDs as these lack standardized structural information necessary for modeling.</p>
<p>Additionally, we should be aware that multiple substances can map to the same compound. This happens when the same chemical structure is submitted by different sources or tested under different conditions. As a result, one CID might be associated with conflicting activity outcomes, for example, one sample labeled as an active agonist and another as inactive. To maintain consistency in the training data, we will remove compounds with conflicting activities.</p>
<p>By cleaning our data based on CID and activity type, we ensure the model learns from reliable, unambiguous data where each chemical structure is uniquely associated with a single activity classification.</p>
<section id="a-drop-substances-without-associated-cids">
<h3>3a. Drop substances without associated CIDs.<a class="headerlink" href="#a-drop-substances-without-associated-cids" title="Link to this heading">#</a></h3>
<p>First, check if there are subtances without associated CIDs. We will used the <code class="docutils literal notranslate"><span class="pre">isna()</span></code> method to identify all rows that are missing values (not available).</p>
<p><strong>Chaining</strong> refers to calling multiple methods one after another on a pandas object. We can <strong>“chain”</strong> this with <code class="docutils literal notranslate"><span class="pre">.sum()</span></code> to count how many are missing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
How many records lack an associated CID? <p>The records without CID are not going to provide us with standardized structural information, so we will remove them from the dataframe.</p>
<p>This is accomplished by using the <code class="docutils literal notranslate"><span class="pre">.dropna()</span></code> method. Since we only want to remove rows where the CID is missing, we can use the <code class="docutils literal notranslate"><span class="pre">subset</span></code> parameter to specify we are targeting only those NA values in the <strong>‘cid’</strong> column.</p>
<p>Look at the output of the previous cell block. If we did the <code class="docutils literal notranslate"><span class="pre">dropna()</span></code> method without indicating which subset we are dropping, we could lose all of our data because the <strong>activity_url</strong> is null for every row in the dataframe!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span> <span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># identify Compounds IDs and Substance IDs. </span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of Substance IDs=&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;sid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of Compound IDs= &#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<p>Check if the NULL values disappeared in the <strong>cid</strong> column. The value should be 0 for that column now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="b-remove-cids-with-conflicting-activities">
<h3>3b. Remove CIDs with conflicting activities<a class="headerlink" href="#b-remove-cids-with-conflicting-activities" title="Link to this heading">#</a></h3>
<p>This code identifies unique CIDs and checks whether multiple values exist in the <strong>activity_summary column</strong>. If conflicting activity summaries are found, the code stores the CID in the <code class="docutils literal notranslate"><span class="pre">cid_conflict</span></code> list and and records the corresponding row indices in <code class="docutils literal notranslate"><span class="pre">idx_conflict</span></code>. Finally, the total number of CIDs with conflicts and total number of rows are output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cid_conflict</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># list to store CIDs with conflicting activities</span>
<span class="n">idx_conflict</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># list to store indices of rows with conflicting activities</span>

<span class="k">for</span> <span class="n">mycid</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span> <span class="p">:</span> <span class="c1"># iterate over each unique Compound ID</span>
    
    <span class="n">outcomes</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span> <span class="n">df</span><span class="o">.</span><span class="n">cid</span> <span class="o">==</span> <span class="n">mycid</span> <span class="p">]</span><span class="o">.</span><span class="n">activity_summary</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span> <span class="c1">#</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="p">:</span> <span class="c1"># if there are multiple unique activity summaries for this CID</span>
        
        <span class="n">idx_tmp</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span> <span class="n">df</span><span class="o">.</span><span class="n">cid</span> <span class="o">==</span> <span class="n">mycid</span> <span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="c1"># get the indices of these rows</span>
        <span class="n">idx_conflict</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">idx_tmp</span><span class="p">)</span> <span class="c1"># add these indices to the conflict list</span>
        <span class="n">cid_conflict</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mycid</span><span class="p">)</span> <span class="c1"># # add the CID to the conflict list</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;#&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cid_conflict</span><span class="p">),</span> <span class="s2">&quot;CIDs with conflicting activities [associated with&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_conflict</span><span class="p">),</span> <span class="s2">&quot;rows (SIDs).]&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To examine which CIDs have conflicting activity data, we can display a portion of the dataframe using the <code class="docutils literal notranslate"><span class="pre">.loc[]</span></code> method. This allows us to select specific rows. In this case, we used the ones listed in <code class="docutils literal notranslate"><span class="pre">idx_conflict</span></code>, which correspond to compounds with inconsistent activity summaries. We’ll chain with <code class="docutils literal notranslate"><span class="pre">.head(10)</span></code> to view just the first 10 of these rows for quick inspection.</p>
<p>This helps us verify the nature of the conflicts and better understand why these entries need to be removed before modeling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx_conflict</span><span class="p">,:]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
Examine the portion of the dataframe above. Why should CID 16043 be removed from the analysis?<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drop the IDs that have conflicting data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">idx_conflict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># After removing the conflicting data, we can check the counts of each activity summary again</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;activity_summary&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># identify Compounds IDs and Substance IDs. </span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of Substance IDs=&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;sid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of Compound IDs= &#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="c-remove-redundant-data">
<h3>3c. Remove redundant data<a class="headerlink" href="#c-remove-redundant-data" title="Link to this heading">#</a></h3>
<p>The code cells in section 3b. do not remove compounds tested multiple times if the testing results are consistent [e.g., active agonist in all samples (substances)].  The rows corresponding to these compounds are redundant, so we want remove them except for only one row for each compound.</p>
<p>To illustrate this, let’s create a sorted dataframe to see some of the redundancies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sorted_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">,</span><span class="s1">&#39;sid&#39;</span><span class="p">,</span><span class="s1">&#39;activity_summary&#39;</span><span class="p">],</span>
                           <span class="n">ascending</span><span class="o">=</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">])</span>
<span class="n">sorted_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
Explore the above displayed sorted dataframe. Identify any CIDs that are repeated, and if they have different <b>SID</b> or <b>activity_outcome</b> values.<p>We will use the <code class="docutils literal notranslate"><span class="pre">drop_duplicates()</span></code> method in pandas to remove any duplicate rows in our dataframe. We can use the <code class="docutils literal notranslate"><span class="pre">subset</span></code> parameter to signify which column to consider when identifying duplicates. In our case, we need unique identifiers to get structural data, so we use <strong>‘cid’</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;cid&#39;</span><span class="p">)</span>  <span class="c1"># remove duplicate rows except for the first occurring row.</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of Substance IDs=&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;sid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of Compound IDs= &#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
Why are the total of SIDs equal to CIDs at this point?</section>
<section id="d-adding-numeric-activity-classes">
<h3>3d. Adding “numeric” activity classes<a class="headerlink" href="#d-adding-numeric-activity-classes" title="Link to this heading">#</a></h3>
<p>In general, machine learning algorithms require both inputs and outputs to be in numerical form.</p>
<p>In our case the input we will be using are molecular structure. We have been working to clean our data to ensure we have valid CIDs that we can use to retrieve SMILES strings and subsequently calculate binary fingerprints as input features.</p>
<p>However. the output of biological activity is currently stored as text labels as active or inactive. To make this data suitable for modeling, we will create a new column called <strong>‘activity’</strong> that assigns these labels as numeric values:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code> for actives (including both active agonists and antagonists)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0</span></code> for inactives</p></li>
</ul>
<p>We combine the two types of active compounds into a single class because our goal is to train a binary classifier that distinguishes between compounds that interact with the target (active) and those that do not (inactive).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;activity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;inactive&#39;</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;activity_summary&#39;</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Check if the new column ‘activity’ is added to (the end of) the data frame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="c1">#new column is added to end of column list, so scroll right in the resulting cell output.</span>
</pre></div>
</div>
</div>
</div>
<p>Double-check the count of active/inactive compounds.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;activity_summary&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;activity&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
Do the number of actives in this output equal the active agonist and active antagonist above?</section>
<section id="e-create-a-smaller-data-frame-that-only-contains-cids-and-activities">
<h3>3e. Create a smaller data frame that only contains CIDs and activities.<a class="headerlink" href="#e-create-a-smaller-data-frame-that-only-contains-cids-and-activities" title="Link to this heading">#</a></h3>
<p>Let’s create a smaller data frame that only contains CIDs and activities.  This data frame will be merged with a data frame containing molecular fingerprint information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_activity</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;cid&#39;</span><span class="p">,</span><span class="s1">&#39;activity&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_activity</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="download-structure-information-for-each-compound-from-pubchem">
<h2>4. Download structure information for each compound from PubChem<a class="headerlink" href="#download-structure-information-for-each-compound-from-pubchem" title="Link to this heading">#</a></h2>
<p>While we could have used the SMILES that were already in our dataframe, the label was PUBCHEM_EXT_DATASOURCE_SMILES indicating that the SMILES may have been provided by the submitter, and not cannonical.  To ensure we have quality data, we will retrieve SMILES from PubChem.</p>
<p>Notice also in the previous dataframe, our CID values all had decimals. That is because when we brought in the data to the dataframe, pandas inferred they data type as <code class="docutils literal notranslate"><span class="pre">float64</span></code>. We can confirm this and create a new list where all the data is of type <code class="docutils literal notranslate"><span class="pre">int</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CIDs are stored in original df dataframe as&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CIDs are stored in df_activity dataframe as&quot;</span><span class="p">,</span> <span class="n">df_activity</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">cids</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">cid</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have a list of CIDs as integers, we can retrive the SMILES from PubChem using the PUG REST API.</p>
<p>Once we have retrieved the SMILES we will store them and their respective CIDs into a new <code class="docutils literal notranslate"><span class="pre">df_smiles</span></code> dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">num_cids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cids</span><span class="p">)</span>

<span class="k">if</span> <span class="n">num_cids</span> <span class="o">%</span> <span class="n">chunk_size</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span>
    <span class="n">num_chunks</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">num_cids</span> <span class="o">/</span> <span class="n">chunk_size</span> <span class="p">)</span>
<span class="k">else</span> <span class="p">:</span>
    <span class="n">num_chunks</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">num_cids</span> <span class="o">/</span> <span class="n">chunk_size</span> <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# CIDs = &quot;</span><span class="p">,</span> <span class="n">num_cids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# CID Chunks = &quot;</span><span class="p">,</span> <span class="n">num_chunks</span><span class="p">,</span> <span class="s2">&quot;(chunked by &quot;</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">,</span> <span class="s2">&quot;)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">io</span><span class="w"> </span><span class="kn">import</span> <span class="n">StringIO</span>

<span class="n">df_smiles</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">list_dfs</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># temporary list of data frames</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_chunks</span><span class="p">)</span> <span class="p">:</span>
    
    <span class="n">idx1</span> <span class="o">=</span> <span class="n">chunk_size</span> <span class="o">*</span> <span class="n">i</span>
    <span class="n">idx2</span> <span class="o">=</span> <span class="n">chunk_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">cidstr</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">cids</span><span class="p">[</span><span class="n">idx1</span><span class="p">:</span><span class="n">idx2</span><span class="p">]</span> <span class="p">)</span>

    <span class="n">url</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/&#39;</span> <span class="o">+</span> <span class="n">cidstr</span> <span class="o">+</span> <span class="s1">&#39;/property/IsomericSMILES/TXT&#39;</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span> <span class="n">StringIO</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">text</span><span class="p">),</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;smiles&#39;</span><span class="p">]</span> <span class="p">)</span>
    <span class="n">list_dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="p">(</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Processing Chunk &quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>   

<span class="c1">#    if ( i == 2 ) : break  #- for debugging</span>

<span class="n">df_smiles</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">list_dfs</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_smiles</span><span class="p">[</span> <span class="s1">&#39;cid&#39;</span> <span class="p">]</span> <span class="o">=</span> <span class="n">cids</span>
<span class="n">df_smiles</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make sure the number of rows in df_smiles is equal to the number of unique CIDs we had previously</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of CIDs in df_smiles:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_smiles</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of unique CIDs in original df:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of CIDs in df_smiles is equal to the number of unique CIDs in the original df:&quot;</span><span class="p">,</span>
       <span class="nb">len</span><span class="p">(</span><span class="n">df_smiles</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># reorder columns to have &#39;cid&#39; first, then &#39;smiles&#39;</span>
<span class="n">df_smiles</span> <span class="o">=</span> <span class="n">df_smiles</span><span class="p">[[</span><span class="s1">&#39;cid&#39;</span><span class="p">,</span><span class="s1">&#39;smiles&#39;</span><span class="p">]]</span>
<span class="n">df_smiles</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Check your understanding</strong>
<p>1)When we requested the SMILES data from PubChem through PUG REST, why did we chunk our data and use time.sleep(.2)?</p>
<p>2)Briefly explain the steps and importance for cleaning the data in the notebook thus far.</p>
<div class="alert alert-block alert-info">
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="part-2-convert-smiles-to-binary-data-for-model-input">
<h1>Part 2: Convert SMILES to Binary Data for Model Input<a class="headerlink" href="#part-2-convert-smiles-to-binary-data-for-model-input" title="Link to this heading">#</a></h1>
<section id="generate-maccs-keys-from-smiles">
<h2>5. Generate MACCS keys from SMILES.<a class="headerlink" href="#generate-maccs-keys-from-smiles" title="Link to this heading">#</a></h2>
<p>Now that we have our SMILES and Output data in the form of biological activity, we need to generate our binary input that describes chemical structure for model training. The presence of a Key is is encoded as <code class="docutils literal notranslate"><span class="pre">1</span></code> for present and <code class="docutils literal notranslate"><span class="pre">0</span></code> for absent.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">rdkit</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chem</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">rdkit.Chem</span><span class="w"> </span><span class="kn">import</span> <span class="n">MACCSkeys</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fps</span><span class="o">=</span><span class="nb">dict</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df_smiles</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()</span> <span class="p">:</span>
    
    <span class="n">mol</span> <span class="o">=</span> <span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">smiles</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">mol</span> <span class="o">==</span> <span class="kc">None</span> <span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Can&#39;t generate MOL object:&quot;</span><span class="p">,</span> <span class="s2">&quot;CID&quot;</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">cid</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">smiles</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fps</span><span class="p">[</span><span class="n">row</span><span class="o">.</span><span class="n">cid</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">row</span><span class="o">.</span><span class="n">cid</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">MACCSkeys</span><span class="o">.</span><span class="n">GenMACCSKeys</span><span class="p">(</span><span class="n">mol</span><span class="p">)</span><span class="o">.</span><span class="n">ToBitString</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate column names</span>
<span class="n">fpbitnames</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">fpbitnames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;cid&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">167</span><span class="p">):</span>   <span class="c1"># from MACCS000 to MACCS166</span>
    <span class="n">fpbitnames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="s2">&quot;maccs&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="p">)</span>

<span class="n">df_fps</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">fps</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">fpbitnames</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_fps</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="merge-activity-data-and-fingerprint-information">
<h2>6. Merge activity data and fingerprint information<a class="headerlink" href="#merge-activity-data-and-fingerprint-information" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_activity</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_fps</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_data</span> <span class="o">=</span> <span class="n">df_activity</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_fps</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;cid&#39;</span><span class="p">),</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;cid&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Check to see if there are any CIDs for which the MACCS keys could not be generated.  They need to be removed from <strong>df_data</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_data</span><span class="p">[</span><span class="n">df_data</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_data</span> <span class="o">=</span> <span class="n">df_data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">df_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Save df_data in CSV for future use.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;df_data.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-info">
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="part-3-machine-learning">
<h1>Part 3: Machine Learning<a class="headerlink" href="#part-3-machine-learning" title="Link to this heading">#</a></h1>
<section id="preparation-for-model-building">
<h2>7. Preparation for model building<a class="headerlink" href="#preparation-for-model-building" title="Link to this heading">#</a></h2>
<p>We are building multiple supervised learning models to predict the biological activity of small molecules. In this context, the input data are represented by MACCS Keys. The output data is the compound’s activity, encoded as <code class="docutils literal notranslate"><span class="pre">1</span></code> for active and <code class="docutils literal notranslate"><span class="pre">0</span></code> for inactive.</p>
<p>The model we are building learns a mathematical relationship between the input features and the output activity. This can be represented by the equation:</p>
<center>y=<i>f</i>(X)</center>
<p>where:</p>
<ul class="simple">
<li><p>y is the predicted activity (the output),</p></li>
<li><p>X is a vector of descriptors (in our case, the MACCS keys),</p></li>
<li><p><em>f</em> is the model that maps features to a predicted outcome.</p></li>
</ul>
<p>We use uppercase X to indicate that the input data is multiple descriptors</p>
<section id="a-loading-the-data-into-x-and-y">
<h3>7a. Loading the data into X and y.<a class="headerlink" href="#a-loading-the-data-into-x-and-y" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we now have a dataframe with CIDS, activities and maccs keys</span>
<span class="n">df_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will put the MACCS Keys into a variable called X_MACCS.<br>
We will put the activity values into a variable called y.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_MACCS</span> <span class="o">=</span> <span class="n">df_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span> <span class="c1"># this is dropping cid and activity and creating a new variable for maccs data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_data</span><span class="p">[</span><span class="s1">&#39;activity&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_MACCS</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>    <span class="c1"># Number of all compounds</span>
<span class="n">y</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>          <span class="c1"># Number of actives</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="b-remove-zero-variance-features">
<h3>7b. Remove zero-variance features<a class="headerlink" href="#b-remove-zero-variance-features" title="Link to this heading">#</a></h3>
<p>Some features in X are not helpful in distinguishing actives from inactives, because they are set ON for all compounds or OFF for all compounds.  Such features need to be removed because they would consume more computational resources without improving the model.</p>
<p>We will use the <code class="docutils literal notranslate"><span class="pre">VarianceThreshold</span></code> method of sklearn to identify which features have a variance of zero or very low. Variance in data represents how spread out the values of a feature are. The <code class="docutils literal notranslate"><span class="pre">threshold</span></code> parameter is set to 0.0 by default, meaning only features with zero variance (constant values across all samples, 100% identical values) are removed.</p>
<div class="alert alert-block alert-info">
<details>
<summary>What if a feature has ≥99% identical values?</summary>
Let’s say a feature is <code>1</code>  in 99.5% of rows and <code>0</code>  in the remaining 0.5%. It does not have zero variance, but the variance is very low.
<p>If you want to remove such near-constant features, you need to set <code>threshold</code> accordingly. In this case the variance is calculated as:</p>
<center>Var(X)=<i>p</i>(1−<i>p</i>)=0.995×(1−0.995)=0.004975<br>
where <i>p</i> is probability of the feature being 1</center>
<p>So to remove this feature, your threshold must be greater than 0.004975, for example:
<code>VarianceThreshold(threshold=0.005)</code></p>
<p>It might be interesting to see how our models change, or time calculating the model changes if we do some prefiltering by adjusting the threshold.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">VarianceThreshold</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_MACCS</span><span class="o">.</span><span class="n">shape</span>  <span class="c1">#- Before removal</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Code to filter out features with low variance and save to a new dataframe</span>
<span class="c1"># Allows us to play with threshold value to remove features with low variance</span>

<span class="n">sel</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.00</span><span class="p">)</span> <span class="c1"># while the default is 0.0, we can set this to a different value.</span>
<span class="n">X_MACCS_filtered</span><span class="o">=</span><span class="n">sel</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_MACCS</span><span class="p">)</span> <span class="c1"># filters and removes columns with variance below the threshold in one step</span>

<span class="c1"># the get_support() method returns a boolean mask indicating which features were kept (True) or removed (False)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">get_support</span><span class="p">()</span> 

<span class="c1">#use the mask to filter the columns in the original DataFrame</span>
<span class="n">kept_features</span> <span class="o">=</span> <span class="n">X_MACCS</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">removed_features</span> <span class="o">=</span> <span class="n">X_MACCS</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span> <span class="c1"># ~ This will give us the features that were removed</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Features removed:&quot;</span><span class="p">,</span> <span class="n">removed_features</span><span class="p">)</span>
<span class="n">X_MACCS_filtered</span><span class="o">.</span><span class="n">shape</span>  <span class="c1">#- After removal</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Check your understanding</strong>
<p>Why is maccs000 removed regardless of threshold level?</p>
</section>
<section id="c-train-test-split-a-9-1-ratio">
<h3>7c. Train-Test-Split (a 9:1 ratio)<a class="headerlink" href="#c-train-test-split-a-9-1-ratio" title="Link to this heading">#</a></h3>
<p>Now that we’ve prepared the dataset, the next step is to divide it into two parts: one for training the model and one for testing it. This is important because we want to evaluate how well the model performs on unseen data, and not just the data it was trained on.</p>
<p>This is typically done by splitting the dataset into two subsets using a specified ratio. Common splits include 80:20 or 70:30, where the larger portion is used for training and the smaller for testing. When the dataset is small or the model requires more examples to learn effectively, a 90:10 split can be helpful.</p>
<p>In the next code section, we will split the data so that 90% goes into the training set and 10% into the test set. The training set is used to build the model, while the test set is used to evaluate how well the model generalizes to new data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> \
    <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_MACCS_filtered</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">3100</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set shape:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;where there are&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;samples, and&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;and&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;activities associated with the training set.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set shape:&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;where there are&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;samples, and&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;and&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;activities associated with the test set.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of active compounds in training set:&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of active compounds in test set:&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="d-balancing-the-training-set">
<h3>7d. Balancing the training set<a class="headerlink" href="#d-balancing-the-training-set" title="Link to this heading">#</a></h3>
<p>Before training a classification model, it is important to examine the number of active versus inactive compounds in the training set. This helps assess whether the dataset is:</p>
<ul class="simple">
<li><p><strong>balanced</strong>, where both classes are represented in roughly equal proportions or,</p></li>
<li><p><strong>unbalanced</strong>, where one class significantly outnumbers the other.</p></li>
</ul>
<p>A balanced dataset is ideal for training because the model can learn to distinguish between both classes effectively. In contrast, an unbalanced dataset may cause the model to become biased toward the majority class, leading to poor performance in predicting the minority class.</p>
<p>By checking the class distribution early, we can decide whether additional steps, such as resampling or using class weights, are needed to improve model fairness and accuracy.</p>
<p>Check the number of actives and inactive compounds in the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# inactives in training set: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# actives in training set:   &quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span><span class="o">/</span><span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;the ratio of inactive to active in training set=&quot;</span><span class="p">,</span> <span class="n">ratio</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-info">
<details>
<summary>How to interpret class balance ratios.</summary>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-right"><p><strong>Ratio</strong></p></th>
<th class="head"><p><strong>How to Interpret the Value</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>1</p></td>
<td><p>Balanced: Roughly equal number of active and inactive. Ideal for training</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>2</p></td>
<td><p>Mild imbalance: 1 active for every 2 inactives. Still manageable, but performance of minority class should be monitored.</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>&gt;5</p></td>
<td><p>Severe imbalance. Model may predict majority class most of the time and ignore the minority class.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="alert alert-block alert-warning">
<strong>Check your understanding</strong>
<p>Is your training set balanced?</p>
<section id="downsampling">
<h4>Downsampling<a class="headerlink" href="#downsampling" title="Link to this heading">#</a></h4>
<p>When majority class in a dataset is unbalanced, downsampling is used select a subset of the majority class to minority class. This helps the model learn to distinguish the classes more fairly. While it reduces data quality, it can improve model performance on the minority class, and prevent biases toward the majority. Downsampling is not without risk, however, as we may be discarding potentially useful information from the majority class.</p>
<p>In the code cell below, we will randomly select from the inactives a number of compounds that is equal to actives.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Indicies of each class&#39; observations</span>
<span class="n">idx_inactives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span> <span class="n">y_train</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">idx_actives</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span> <span class="n">y_train</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Number of observations in each class</span>
<span class="n">num_inactives</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_inactives</span><span class="p">)</span>
<span class="n">num_actives</span>   <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_actives</span><span class="p">)</span>

<span class="c1"># Randomly sample from inactives without replacement</span>
<span class="c1"># setting size to the number of actives ensures we downsample inactives to match the number of actives</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">idx_inactives_downsampled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">idx_inactives</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_actives</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Join together downsampled inactives with actives</span>
<span class="c1"># vstack and hstack are used to combine arrays vertically and horizontally, respectively</span>
<span class="c1"># this ensures that the rows from downsampled inactives and actives are combined correctly</span>
<span class="c1"># we use vstack for a 2D array (X_train) and hstack for a 1D array (y_train)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">X_train</span><span class="p">[</span><span class="n">idx_inactives_downsampled</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="n">idx_actives</span><span class="p">]))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">y_train</span><span class="p">[</span><span class="n">idx_inactives_downsampled</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">idx_actives</span><span class="p">]))</span>

<span class="c1">#confirm the downsampling worked</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# inactives : &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# actives   : &quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span><span class="o">/</span><span class="n">y_train</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;the ratio of active to inactive =&quot;</span><span class="p">,</span> <span class="n">ratio</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="c1"># check to see the number of samples and features in the training set</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set shape:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;where there are&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;samples, and&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;and&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;activities associated with the training set.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="build-a-model-using-the-training-set">
<h2>8. Build a model using the training set.<a class="headerlink" href="#build-a-model-using-the-training-set" title="Link to this heading">#</a></h2>
<p>Now we are ready to build predictive models using machine learning algorithms available in the scikit-learn library (https://scikit-learn.org/).  This notebook will use Naïve Bayes and decision tree, because they are relatively fast and simple.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">BernoulliNB</span>        <span class="c1">#-- Naïve Bayes</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>    <span class="c1">#-- Decision Tree</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span> <span class="c1">#provides detailed report that includes precision and sensitivity</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">confusion_matrix</span>      <span class="c1"># gives a 2x2 matrix for true netatives, false positives, false negatives and true positives</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>        <span class="c1"># computes accuracy = number of correct preictions/total number of preditions</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">roc_auc_score</span>         <span class="c1"># Computs Area under the ROC curve, evaluates trade-off of true positive rate and false positive rate</span>
</pre></div>
</div>
</div>
</div>
<section id="a-naive-bayes">
<h3>8a. Naïve Bayes<a class="headerlink" href="#a-naive-bayes" title="Link to this heading">#</a></h3>
<p>Bernoulli Naïve Bayes is a probabilistic classification algorithm based on Bayes’ Theorem, well-suited for binary feature vectors such as molecular fingerprints. In cheminformatics, it is often applied to classify molecules (e.g., active vs. inactive) based on structural features represented as binary indicators — such as the presence or absence of specific substructures captured by MACCS keys or other molecular fingerprints. The algorithm assumes that features are conditionally independent given the class label and models each feature using a Bernoulli (0 or 1) distribution. During training, it learns the likelihood of each structural feature being present within each class. Despite its simplicity and the strong independence assumption, Bernoulli Naïve Bayes is efficient and effective for high-dimensional molecular data, making it a useful baseline model for structure-activity classification tasks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up the NB classification model. Bernoulli is specific for binary features (0,1) </span>
<span class="n">clf_NB</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">()</span>            
</pre></div>
</div>
</div>
</div>
<p>The next line of code trains (or “fits”) the Bernoulli Naïve Bayes classifier using the training data.</p>
<p><strong>Parameters:</strong><br>
X_train: The input features for training. This is a 2D array (DataFrame) where:</p>
<ul class="simple">
<li><p>Rows = individual training samples</p></li>
<li><p>Columns = features (typically <code class="docutils literal notranslate"><span class="pre">0</span></code>s and <code class="docutils literal notranslate"><span class="pre">1</span></code>s for BernoulliNB)</p></li>
</ul>
<p>y_train: The target labels (classes) corresponding to each row in X_train.</p>
<p>For each feature, and for each class label, the classifier estimates the probability that the feature is 1 (present) given the class.</p>
<p>It also calculates the prior probabilities for each class based on how often they appear in y_train.</p>
<p>These are used later in predictions via Bayes’ Theorem.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the model by fitting it to the data.</span>
<span class="n">clf_NB</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">X_train</span> <span class="p">,</span><span class="n">y_train</span> <span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<p>The next code cell sets up two variables:<br>
y_true: the actual labels from the training set (i.e., ground truth)<br>
y_pred: the predicted labels that the trained model gives for X_train<br>
So you’re essentially preparing for evaluation of how well the model performs on the training data.<br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply the model to predict the training compound&#39;s activity.</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">X_train</span> <span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<p>Next, we will use a confusion matrix to evaluate how well our model predicts active and inactive compounds. A confusion matrix compares the actual labels (from the test set) with the predicted labels (from the model) and summarizes the results in a structured way.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">confusion_matrix()</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn.metrics</span></code> to generate this matrix. For binary classification, the output is a 2×2 NumPy array, commonly referred to as CMat, with the following layout:</p>
<div style="font-family: Arial, sans-serif; margin-top: 20px;">
<center>
  <h4>Confusion Matrix (Binary Classification)</h4>
  <table border="1" cellspacing="0" cellpadding="10" style="border-collapse: collapse; text-align: center;">
    <tr>
      <th rowspan="2">Actual</th>
      <th colspan="2">Predicted</th>
    </tr>
    <tr>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>0</th>
      <td>TN<br><small>True Negative</small></td>
      <td>FP<br><small>False Positive</small></td>
    </tr>
    <tr>
      <th>1</th>
      <td>FN<br><small>False Negative</small></td>
      <td>TP<br><small>True Positive</small></td>
    </tr>
  </table>
</center>
</div>
<p>This matrix gives us insight into the types of errors the model makes and is the foundation for calculating metrics like accuracy, precision, recall, and F1-score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span> <span class="c1">#-- generate confusion matrix</span>
<span class="n">CMat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span>   
<span class="nb">print</span><span class="p">(</span><span class="n">CMat</span><span class="p">)</span>    <span class="c1"># [[TN, FP], </span>
               <span class="c1">#  [FN, TP]]</span>
<span class="c1"># Extracting TN, FP, FN, TP from the confusion matrix               </span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># True Negatives</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># False Positives</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># False Negatives</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># True Positives</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Negatives (TN):&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Positives (FP):&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Negatives (FN):&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Positives (TP):&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total predictions:&quot;</span><span class="p">,</span> <span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Interpreting the confusion matrix</strong>
<ol class="arabic simple">
<li><p>How does the sum of the predictions relate to number of molecules the training set?</p></li>
<li><p>How many actives are in the training set? How many would a perfect model predict? Is this predicting more or less?</p></li>
<li><p>How many inactives are in the training set? How many would a perfect model predict? Is this predicting more or less?</p></li>
<li><p>Is this model perfect? Is it <em>“good enough”</em>?</p></li>
</ol>
<p>To answer the question “Is the model good enough?”, we rely on key metrics calculated from the confusion matrix:</p>
<ul class="simple">
<li><p>Accuracy: The proportion of all predictions that were correct = (TP+TN)/(TP+TN+FP+FN)</p></li>
<li><p>Precision: Of the compounds the model predicted as active, how many were actually active? = TP / (TP + FP)</p></li>
<li><p>Sensitivity: Of the truly active compounds, how many did the model correctly identify? = TP / (TP + FN)</p></li>
<li><p>Specificity: measures how well model identifies actual negatives = TN / (TN + FP )</p></li>
<li><p>Balanced accuracy: averages sensitivity and specificity = (sens + spec) / 2</p></li>
<li><p>F1-score: Harmonic mean of precision and recall =2 × (Precision × Specificity) / (Precision + Specificity)</p></li>
<li><p>AUC-ROC (Area Under the Receiver Operating Characteristic Curve)- Measures the model’s ability to distinguish between classes</p></li>
</ul>
<p>These metrics help us assess not only overall accuracy but also the types of errors the model makes. For example:</p>
<ul class="simple">
<li><p>Is the model missing many actives? (high FN → low sensitivity)</p></li>
<li><p>Is it misclassifying inactives as actives? (high FP → low precision)</p></li>
</ul>
<p>Understanding these trade-offs is essential for deciding whether the model is acceptable, especially in fields like drug discovery, where missing an active might be more costly than flagging a few false positives.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span> <span class="c1">#correct predictions/total predictions = (TP+TN)/(TP+TN+FP+FN)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># precision = TP / (TP + FP) measures how well model identifies actual positives</span>
<span class="n">sens</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>    <span class="c1"># sensitivity = TP / (FN + TP) measures how well model identifies actual positives</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># specificity = TN / (TN + FP)measures how well model identifies actual negatives</span>
<span class="n">bacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">sens</span> <span class="o">+</span> <span class="n">spec</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>    <span class="c1">#averages sensititivy and specificity</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">prec</span> <span class="o">*</span> <span class="n">sens</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec</span> <span class="o">+</span> <span class="n">sens</span><span class="p">)</span>  <span class="c1"># F1 score is the harmonic mean of precision and sensitivity</span>

<span class="n">y_score</span> <span class="o">=</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span> <span class="n">X_train</span> <span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1">#returns proability of each class, [:, 1] extracts the probability of the positive class (label 1) for each sample.</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span> <span class="p">)</span> <span class="c1">#measures how well the model ranks psitive vs negative samples. AUC = 1.0 → perfect model; AUC = 0.5 → random guessing.</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set performance metrics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy          = </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># how accurate is the model overall</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision         = </span><span class="si">{</span><span class="n">prec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it identifies actual positives (precision)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity       = </span><span class="si">{</span><span class="n">sens</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it catches positives (sensitivity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Specificity       = </span><span class="si">{</span><span class="n">spec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it avoids false negatives (specificity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Balanced Accuracy = </span><span class="si">{</span><span class="n">bacc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How balanced its performance is across classes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score          = </span><span class="si">{</span><span class="n">f1_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># Harmonic mean of precision and sensitivity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC-ROC           = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1">#How well it ranks predictions (AUC)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-info">
<details>
<summary>Classification Metrics Interpretation Guide</summary>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p><strong>Metric</strong></p></th>
<th class="head text-left"><p><strong>What It Measures</strong></p></th>
<th class="head text-left"><p><strong>How to Interpret the Value</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Accuracy</strong></p></td>
<td class="text-left"><p>Overall % of correct predictions</p></td>
<td class="text-left"><p>✅ ≥ 0.80 = High accuracy<br>⚠️ 0.60–0.79 = Moderate <em>Can be misleading with class imbalance</em> <br>🔴 &lt; 0.60 = Poor accuracy</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Balanced Accuracy</strong></p></td>
<td class="text-left"><p>Avg. of sensitivity (recall) and specificity</p></td>
<td class="text-left"><p>✅ ≥ 0.80 = Strong<br>⚠️ 0.60–0.79 = Moderate<br>🔴 &lt; 0.60 = Poor</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Sensitivity</strong> (Recall)</p></td>
<td class="text-left"><p>% of actual actives correctly predicted (TPR / Recall)</p></td>
<td class="text-left"><p>✅ ≥ 0.80 = Few missed positives<br>⚠️ 0.60–0.80 = Moderate<br>🔴 &lt; 0.60 = Many positives missed</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Specificity</strong></p></td>
<td class="text-left"><p>% of actual inactives correctly predicted (TNR)</p></td>
<td class="text-left"><p>✅ ≥ 0.80 = Few false positives<br>⚠️ 0.60–0.79 = Moderate<br>🔴 &lt; 0.60 = Too many false positives</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Precision</strong></p></td>
<td class="text-left"><p>% of predicted positives that are truly positive</p></td>
<td class="text-left"><p>✅ ≥ 0.80 = Few false positives<br>⚠️ 0.60–0.79 = Moderate<br>🔴 &lt; 0.60 = Too many false positives</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>F1-score</strong></p></td>
<td class="text-left"><p>harmonic Meen of precision and recall</p></td>
<td class="text-left"><p>✅ ≥ 0.75 = Few false Positives<br>⚠️ 0.60–0.79 = Moderate<br>🔴 &lt; 0.60 = Too many false positives</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>AUC-ROC</strong></p></td>
<td class="text-left"><p>Ability to rank actives above inactives across thresholds</p></td>
<td class="text-left"><p>✅ ≥ 0.80 = Strong discrimination<br>⚠️ 0.70–0.79 = Acceptable<br>🔴 &lt; 0.70 = Weak model<br>🚫 ~0.50 = Random guessing</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Quick Rules of Thumb:</strong></p>
<ul class="simple">
<li><p>If accuracy is high but balanced accuracy is low → suspect class imbalance.</p></li>
<li><p>Use balanced accuracy when your dataset has a lot more inactives than actives.</p></li>
<li><p>Sensitivity is important when missing an active could be costly (e.g., in drug screening).</p></li>
<li><p>Specificity is important when false positives are costly (e.g., expensive follow-up experiments).</p></li>
<li><p>AUC-ROC gives a broader view of model quality — useful even when you’re not picking a classification threshold yet.</p></li>
</ul>
<div class="alert alert-block alert-warning">
<strong>Interpreting key metrics from the confusion matrix</strong>
<p>Using the Classification Metrics Interpretation Guide, how well did the model predict those molecules in the training set?</p>
<p>While these values represent ability to predict the test set, the real performance of the model should be evaluated with the test set data, which are not used for model training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#-- Apply the model to predict the test set compounds&#39; activity.</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CMat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span>    <span class="c1">#-- generate confusion matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="n">CMat</span><span class="p">)</span>    <span class="c1"># [[TN, FP], </span>
               <span class="c1">#  [FN, TP]]</span>

<span class="c1"># Extracting TN, FP, FN, TP from the confusion matrix               </span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># True Negatives</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># False Positives</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># False Negatives</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># True Positives</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Negatives (TN):&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Positives (FP):&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Negatives (FN):&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Positives (TP):&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total predictions:&quot;</span><span class="p">,</span> <span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># metrics for the test set</span>
<span class="n">acc</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span> <span class="c1">#correct predictions/total predictions = (TP+TN)/(TP+TN+FP+FN)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># precision = TP / (TP + FP) measures how well model identifies actual positives</span>
<span class="n">sens</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>    <span class="c1"># sensitivity = TP / (FN + TP) measures how well model identifies actual positives</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># specificity = TN / (TN + FP)measures how well model identifies actual negatives</span>
<span class="n">bacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">sens</span> <span class="o">+</span> <span class="n">spec</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>    <span class="c1">#averages sensititivy and specificity</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">prec</span> <span class="o">*</span> <span class="n">sens</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec</span> <span class="o">+</span> <span class="n">sens</span><span class="p">)</span>  <span class="c1"># F1 score is the harmonic mean of precision and sensitivity</span>

<span class="n">y_score</span> <span class="o">=</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span> <span class="n">X_test</span> <span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1">#returns proability of each class, [:, 1] extracts the probability of the positive class (label 1) for each sample.</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span> <span class="p">)</span> <span class="c1">#measures how well the model ranks psitive vs negative samples. AUC = 1.0 → perfect model; AUC = 0.5 → random guessing.</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Set Metrics&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy          = </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># how accurate is the model overall</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision         = </span><span class="si">{</span><span class="n">prec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it identifies actual positives (precision)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity       = </span><span class="si">{</span><span class="n">sens</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it catches positives (sensitivity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Specificity       = </span><span class="si">{</span><span class="n">spec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it avoids false negatives (specificity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Balanced Accuracy = </span><span class="si">{</span><span class="n">bacc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How balanced its performance is across classes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score          = </span><span class="si">{</span><span class="n">f1_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># Harmonic mean of precision and sensitivity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC-ROC           = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1">#How well it ranks predictions (AUC)</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Check the number of actives and inactive compounds in the test set.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# inactives : &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_test</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# actives   : &quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_test</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span><span class="o">/</span><span class="n">y_test</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;the ratio of active to inactive =&quot;</span><span class="p">,</span> <span class="n">ratio</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Interpreting key metrics from the confusion matrix for the Test set</strong>
<ol class="arabic simple">
<li><p>Using the Classification Metrics Interpretation Guide, how well did the model predict those molecules in the test set?</p></li>
<li><p>Why is the balanced accuracy different from the accuracy in the test set example?</p></li>
<li><p>How does our precision compare from the training to the test set?</p></li>
<li><p>How do the F1 values compare from training to test set?</p></li>
</ol>
<p>Some additional performance information may be obtained using scikit-learn’s <strong>classification_report()</strong>.  It gives a summary of some of the items we have calculated so far (precision, recall/sensitivity, F1 and number of instances in each class called support). This can be very helpful when looking at imbalanced sets, like our test set, because it includes data for each class as well as weighted averages to take into account the the proportion of classes.  This allows for a more nuanced evaluation of the model across classes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-info">
<details>
<summary>Interpreting additional metric information provided in the classification_report</summary>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>What It Measures</p></th>
<th class="head"><p>Interpretation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Support</p></td>
<td><p>Number of actual instances of the class in the dataset</p></td>
<td><p>Not a metric. It just tells you how many samples belong to each class.</p></td>
</tr>
</tbody>
</table>
</div>
<section id="id1">
<h4><a class="headerlink" href="#id1" title="Link to this heading">#</a></h4>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>What It Means</p></th>
<th class="head"><p>When to Use / Why It Matters</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Macro Avg</strong></p></td>
<td><p>Average of each metric (precision, recall, F1) calculated <strong>per class</strong>, without considering class size.</p></td>
<td><p>Treats all classes equally. Highlights poor performance on minority classes. Good for imbalanced datasets when fairness across classes matters.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Weighted Avg</strong></p></td>
<td><p>Average of each metric weighted by the number of instances (<strong>support</strong>) in each class.</p></td>
<td><p>Reflects overall performance, but may hide poor performance on small classes. Good when class proportions should affect the overall score.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="alert alert-block alert-warning">
<strong>Interpreting key metrics from the classification report for the Test set</strong>
<ol class="arabic simple">
<li><p>How well does the model predict inactives in the test set?</p></li>
<li><p>How well does the model predict actives in the test set?</p></li>
</ol>
<p><strong>Let’s predict if a molecule is active!</strong></p>
<p>We can use the model we created to determine if a molecule is active or inactive the enzyme. The following lines of code define SMILES to test. Some of the following are in the training set and active, some in the training set and inactive, and some are outside the training set. A returned value of <code class="docutils literal notranslate"><span class="pre">1</span></code> = active, and <code class="docutils literal notranslate"><span class="pre">0</span></code> = inactive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Define new SMILES string and view</span>
<span class="n">new_smiles</span> <span class="o">=</span> <span class="s2">&quot;CC(=O)OC1=CC=CC=C1C(=O)O&quot;</span> <span class="c1"># CID 2242 aspirin should be INactive</span>
<span class="c1">#new_smiles = &quot;C1=CC=C(C=C1)C(C2=CC=CC=C2)(C3=CC=CC=C3Cl)N4C=CN=C4&quot; # CID = 2812 should be active</span>
<span class="c1">#new_smiles = &quot;C1=CC=C(C(=C1)C2=NC(=NO2)C3=CC=NC=C3)Cl&quot; #CID 65758 should be active</span>
<span class="c1">#new_smiles = &quot;C1=CC(=CC=C1C2=COC3=CC(=CC(=C3C2=O)O)O)O&quot; #CID 5280961 should be active</span>
<span class="c1">#new_smiles = &quot;CN(C1CCN(CC1)C2=NC3=CC=CC=C3N2CC4=CC=C(C=C4)F)C5=NC=CC(=O)N5&quot; #CID 65906 should be INactive</span>
<span class="c1">#new_smiles = &quot;C1=CNC(=O)NC1=O&quot; #CID 1174 should be INactive</span>
<span class="c1">#new_smiles = &quot;CCCCCC1=CC(=C2C=CC(OC2=C1)(C)CCC=C(C)C)O&quot; #CID30219 not in datbase (CBC)</span>
<span class="c1">#new_smiles = &quot;C[C@H]1C[C@@H](C(=O)[C@@H](C1)[C@@H](CC2CC(=O)NC(=O)C2)O)C&quot; #CID 6197 should be active</span>
<span class="c1">#new_smiles = &quot;CCCCCC1=CC(=C2[C@@H]3C=C(CC[C@H]3C(OC2=C1)(C)C)C)O&quot; #CID16078 in database and should be active (THC)</span>
<span class="c1">#new_smiles = &quot;COC1=CC(=CC(=C1OC)OC)CCN&quot; #CID4076 not in database (mescaline)</span>
<span class="c1">#new_smiles = &quot;CC1=C(C(CCC1)(C)C)/C=C/C(=C/C=C/C(=C/CO)/C)/C&quot; # vitamin A not in database</span>
<span class="n">mol</span> <span class="o">=</span> <span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">new_smiles</span><span class="p">)</span>
<span class="n">mol</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">rdkit.DataStructs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConvertToNumpyArray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">fp</span> <span class="o">=</span> <span class="n">MACCSkeys</span><span class="o">.</span><span class="n">GenMACCSKeys</span><span class="p">(</span><span class="n">mol</span><span class="p">)</span>
<span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span> 
<span class="n">ConvertToNumpyArray</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="n">arr</span><span class="p">)</span>
<span class="n">arr_filtered</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">arr_filtered</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Testing the model</strong>
<p>Test all the new_smiles in the model and add your own SMILES to test the model. Additional molecules you might want to test are androgens (like androstenedione) as they are key substrates for this enzyme. We also know that hydrogen bond donors and acceptors as well as aromatic features are important for interaction with the active site. Formestane and exmestane are known inhibitors. They may or may not be in the training set. It would be interesting to test them here.</p>
<p>How well is the Bernoulli Naïve Bayes model doing at your predictions? Do you trust it? If you are not satisfied, what would you do to improve it?</p>
<p>Now that we have trained a model, we should save it for future use to avoid retraining. This can be achieved using either the <code class="docutils literal notranslate"><span class="pre">pickle</span></code> and <code class="docutils literal notranslate"><span class="pre">joblib</span></code> libraries. While <code class="docutils literal notranslate"><span class="pre">pickle</span></code> is the standard python library, <code class="docutils literal notranslate"><span class="pre">joblib</span></code> is often preferred for models with large NumPy arrays, such as our MACCS Keys, because it is more efficient for handling large data structures.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># How to save the model using joblib</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">clf_NB</span> <span class="c1">#our Naive Bayes model</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;clf_NB_model.joblib&#39;</span> <span class="c1"># give our model a name for the file</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span> <span class="c1"># save the model to a file</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># How to load the model using joblib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">joblib</span>
<span class="n">savedmodel</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="c1"># load the model from the file</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model loaded from file.&quot;</span><span class="p">)</span>


<span class="c1"># Use the loaded model to make predictions on the test set</span>
<span class="c1"># This assumes that X_test is already defined and preprocessed in the same way as during training</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">savedmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

<span class="c1"># Use the loaded model to make predictions on a new SMILES string</span>
<span class="c1"># This assumes that the new SMILES string is preprocessed in the same way as during training</span>
<span class="n">new_smiles</span> <span class="o">=</span> <span class="s2">&quot;CC(=O)OC1=CC=CC=C1C(=O)O&quot;</span> <span class="c1"># CID 2242 aspirin should be INactive</span>
<span class="n">mol</span> <span class="o">=</span> <span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">new_smiles</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">rdkit.DataStructs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConvertToNumpyArray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">fp</span> <span class="o">=</span> <span class="n">MACCSkeys</span><span class="o">.</span><span class="n">GenMACCSKeys</span><span class="p">(</span><span class="n">mol</span><span class="p">)</span>
<span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span> 
<span class="n">ConvertToNumpyArray</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="n">arr</span><span class="p">)</span>
<span class="n">arr_filtered</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">savedmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">arr_filtered</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="b-decision-tree">
<h3>8b Decision Tree<a class="headerlink" href="#b-decision-tree" title="Link to this heading">#</a></h3>
<p>Decision Tree Classification is a machine learning algorithm that predicts whether a molecule is active or inactive by asking a series of yes/no questions based on its features. We will employ this method to look for MACCS Keys. The algorithm builds a tree-like model where each question splits the data to better separate active from inactive compounds. It chooses the questions based on how well they divide the data into pure groups. When a group is pure, it will mostly contain molecules of one class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up the DT classification model</span>
<span class="n">clf_DT</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span> <span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the model by fitting it to the data (using the default values for all parameters)</span>
<span class="c1"># we are using the same training data as before</span>
<span class="n">clf_DT</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">X_train</span> <span class="p">,</span><span class="n">y_train</span> <span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply the model to predict the training compound&#39;s activity.</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">clf_DT</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">X_train</span> <span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate confusion matrix</span>
<span class="n">CMat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span>   
<span class="nb">print</span><span class="p">(</span><span class="n">CMat</span><span class="p">)</span>    <span class="c1"># [[TN, FP], </span>
               <span class="c1">#  [FN, TP]]</span>
<span class="c1"># Extracting TN, FP, FN, TP from the confusion matrix               </span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># True Negatives</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># False Positives</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># False Negatives</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># True Positives</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Negatives (TN):&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Positives (FP):&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Negatives (FN):&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Positives (TP):&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total predictions:&quot;</span><span class="p">,</span> <span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span> <span class="c1">#correct predictions/total predictions = (TP+TN)/(TP+TN+FP+FN)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># precision = TP / (TP + FP) measures how well model identifies actual positives</span>
<span class="n">sens</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>    <span class="c1"># sensitivity = TP / (FN + TP) measures how well model identifies actual positives</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># specificity = TN / (TN + FP)measures how well model identifies actual negatives</span>
<span class="n">bacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">sens</span> <span class="o">+</span> <span class="n">spec</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>    <span class="c1">#averages sensititivy and specificity</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">prec</span> <span class="o">*</span> <span class="n">sens</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec</span> <span class="o">+</span> <span class="n">sens</span><span class="p">)</span>  <span class="c1"># F1 score is the harmonic mean of precision and sensitivity</span>

<span class="n">y_score</span> <span class="o">=</span> <span class="n">clf_DT</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span> <span class="n">X_train</span> <span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1">#returns proability of each class, [:, 1] extracts the probability of the positive class (label 1) for each sample.</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span> <span class="p">)</span> <span class="c1">#measures how well the model ranks psitive vs negative samples. AUC = 1.0 → perfect model; AUC = 0.5 → random guessing.</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set performance metrics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy          = </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># how accurate is the model overall</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision         = </span><span class="si">{</span><span class="n">prec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it identifies actual positives (precision)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity       = </span><span class="si">{</span><span class="n">sens</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it catches positives (sensitivity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Specificity       = </span><span class="si">{</span><span class="n">spec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it avoids false negatives (specificity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Balanced Accuracy = </span><span class="si">{</span><span class="n">bacc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How balanced its performance is across classes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score          = </span><span class="si">{</span><span class="n">f1_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># Harmonic mean of precision and sensitivity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC-ROC           = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1">#How well it ranks predictions (AUC)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Interpreting key metrics from the confusion matrix</strong>
<p>Using the Classification Metrics Interpretation Guide, how well did the decision tree model predict those molecules in the training set?</p>
<p>Let’s test the molecules in the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">clf_DT</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>    <span class="c1">#-- Apply the model to predict the test set compounds&#39; activity.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate confusion matrix</span>
<span class="n">CMat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span>   
<span class="nb">print</span><span class="p">(</span><span class="n">CMat</span><span class="p">)</span>    <span class="c1"># [[TN, FP], </span>
               <span class="c1">#  [FN, TP]]</span>
<span class="c1"># Extracting TN, FP, FN, TP from the confusion matrix               </span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># True Negatives</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># False Positives</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># False Negatives</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># True Positives</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Negatives (TN):&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Positives (FP):&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Negatives (FN):&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Positives (TP):&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total predictions:&quot;</span><span class="p">,</span> <span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span> <span class="c1">#correct predictions/total predictions = (TP+TN)/(TP+TN+FP+FN)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># precision = TP / (TP + FP) measures how well model identifies actual positives</span>
<span class="n">sens</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>    <span class="c1"># sensitivity = TP / (FN + TP) measures how well model identifies actual positives</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># specificity = TN / (TN + FP)measures how well model identifies actual negatives</span>
<span class="n">bacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">sens</span> <span class="o">+</span> <span class="n">spec</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>    <span class="c1">#averages sensititivy and specificity</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">prec</span> <span class="o">*</span> <span class="n">sens</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec</span> <span class="o">+</span> <span class="n">sens</span><span class="p">)</span>  <span class="c1"># F1 score is the harmonic mean of precision and sensitivity</span>

<span class="n">y_score</span> <span class="o">=</span> <span class="n">clf_DT</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span> <span class="n">X_test</span> <span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1">#returns proability of each class, [:, 1] extracts the probability of the positive class (label 1) for each sample.</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span> <span class="p">)</span> <span class="c1">#measures how well the model ranks psitive vs negative samples. AUC = 1.0 → perfect model; AUC = 0.5 → random guessing.</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set performance metrics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy          = </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># how accurate is the model overall</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision         = </span><span class="si">{</span><span class="n">prec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it identifies actual positives (precision)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity       = </span><span class="si">{</span><span class="n">sens</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it catches positives (sensitivity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Specificity       = </span><span class="si">{</span><span class="n">spec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it avoids false negatives (specificity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Balanced Accuracy = </span><span class="si">{</span><span class="n">bacc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How balanced its performance is across classes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score          = </span><span class="si">{</span><span class="n">f1_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># Harmonic mean of precision and sensitivity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC-ROC           = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1">#How well it ranks predictions (AUC)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Interpreting key metrics from the confusion matrix</strong>
<p>Using the Classification Metrics Interpretation Guide, how well did the decision tree model predict those molecules in the test set?</p>
<p>Such high performance on the training set, especially for a flexible model like a decision tree,  is often a sign of <strong>overfitting</strong>.</p>
<p>When applied to predict the activity of the <strong>training</strong> compounds, the DT classifier resulted in very high scores (&gt;0.99) for all five performance measures considered here. The model may have memorized the training data, especially if the tree is very deep or was not pruned. This would result in poor generalization to new, unseen data. As we saw in the test set, the model performed poorly, which is why <strong>test set</strong> evaluation is critical.</p>
</section>
</section>
<section id="model-building-through-cross-validation">
<h2>9. Model building through cross-validation<a class="headerlink" href="#model-building-through-cross-validation" title="Link to this heading">#</a></h2>
<p>In the above section, the models were developed using the default values for many optional hyperparameters, which cannot be learned by the training algorithm.  For example, when building a <strong>decision tree</strong> model, one should specify how deep the <em>tree</em> should be, how many compounds should be allowed in a <em>single leaf</em>, what is the minimum number of compounds in a <em>single leaf</em>, etc.</p>
<p>Grid search and cross-validation are techniques used together to find the best settings for a machine learning model and ensure it generalizes well to new data. Decision trees have additional settings called hyperparameters. These are values that control how the model learns (e.g., the maximum depth of a decision tree, or how many samples are needed to split a node). These are not learned from the data but must be chosen manually. <strong>Grid search</strong> is a method that systematically tries different combinations of hyperparameter values to see which perform best.</p>
<p>To avoid relying on just one train/test split, cross-validation divides the training data into several folds (often 5 or 10), training the model on some folds and validating on the rest, rotating through all folds. This gives a more reliable estimate of model performance. When used together, grid search with cross-validation helps find the best hyperparameter combination while reducing the risk of overfitting.</p>
<p>The cells below demonstrate how to perform hyperparameter optimization through 10-fold cross-validation.  In this example, five values for each of three hyperparameters used in the decision tree are considered (max_depth, min_samples_split, and min_samples_leaf), resulting in a total of 125 combination of the parameter values (= 5 x 5 x 5).  For each combination, 10 models are generated (through 10-fold cross validation) and the average performance will be tracked.  The goal is to find the parameter value combination that results in the highest average performance score (e.g., ‘roc_auc’) from the 10-fold cross validation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#GridSearchCV stands for Grid Search with Cross-Validation.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#For each model configuration, calculate both ROC-AUC and balanced accuracy</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[</span> <span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="s1">&#39;balanced_accuracy&#39;</span> <span class="p">]</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ncvs</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1">#sets number of cross-validation folds to 10, the training set is split into 10 parts. In each iteration, the model is trained on 9 parts and validated on the remaining 1.</span>
                        <span class="c1"># np.linspace() to create evenly spaced integer values in the given ranges.</span>
<span class="n">max_depth_range</span>         <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span> <span class="p">)</span>  <span class="c1">#Maximum depth of the tree (e.g., [3, 4, 5, 6, 7])</span>
<span class="n">min_samples_split_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span> <span class="p">)</span>  <span class="c1"># Minimum number of samples needed to split a node</span>
<span class="n">min_samples_leaf_range</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span> <span class="p">)</span>  <span class="c1">#Minimum number of samples needed to be a leaf node</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth_range</span><span class="p">,</span>                     <span class="c1">#This is a dictionary mapping parameter names to lists of values to try.</span>
                   <span class="n">min_samples_split</span><span class="o">=</span><span class="n">min_samples_split_range</span><span class="p">,</span>     <span class="c1">#GridSearchCV will try every combination of the 5 × 5 × 5 = 125 settings.</span>
                   <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_samples_leaf_range</span> <span class="p">)</span>

<span class="n">clf_DT_CV</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span> <span class="p">),</span>     <span class="c1">#creates base model to optimize on AUC and balanced accuracy</span>
                    <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ncvs</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span>
                    <span class="n">return_train_score</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>   
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This cell will take some time to run. In testing it took just over a 1 minute, but that will </span>
<span class="c1"># depend on user hardware.</span>
<span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="p">)</span>   <span class="c1">#triggers the full grid search with cross-validation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameter set&quot;</span><span class="p">,</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span> <span class="c1">#prints the best-performing hyperparameters. Tells us which combo gives highest CV and used for future predict.</span>
</pre></div>
</div>
</div>
</div>
<p>If necessary, it is possible to look into the performance data for each parameter value combination (stored in <strong>clf.cv_results_</strong>), as shown in the following cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">means_1a</span> <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_train_roc_auc&#39;</span><span class="p">]</span> <span class="c1">#Gives mean and STDV for AUC for training data </span>
<span class="n">stds_1a</span>  <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_train_roc_auc&#39;</span><span class="p">]</span>

<span class="n">means_1b</span> <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_roc_auc&#39;</span><span class="p">]</span> <span class="c1">#Gives mean and STDV for AUC for test data </span>
<span class="n">stds_1b</span>  <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_roc_auc&#39;</span><span class="p">]</span>

<span class="n">means_2a</span> <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_train_balanced_accuracy&#39;</span><span class="p">]</span> <span class="c1">#Gives mean and STDV for Balanced accuracy for training data </span>
<span class="n">stds_2a</span>  <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_train_balanced_accuracy&#39;</span><span class="p">]</span>

<span class="n">means_2b</span> <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_balanced_accuracy&#39;</span><span class="p">]</span>  <span class="c1">#Gives mean and STDV for Balanced accuracy  for test data </span>
<span class="n">stds_2b</span>  <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_balanced_accuracy&#39;</span><span class="p">]</span>

<span class="n">iterobjs</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span> <span class="n">means_1a</span><span class="p">,</span> <span class="n">stds_1a</span><span class="p">,</span> <span class="n">means_1b</span><span class="p">,</span> <span class="n">stds_1b</span><span class="p">,</span>           <span class="c1">#Combines all the relevant stats with their corresponding parameter combinations into one iterable.</span>
                <span class="n">means_2a</span><span class="p">,</span> <span class="n">stds_2a</span><span class="p">,</span> <span class="n">means_2b</span><span class="p">,</span> <span class="n">stds_2b</span><span class="p">,</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span> <span class="p">)</span>

<span class="k">for</span> <span class="n">m1a</span><span class="p">,</span> <span class="n">s1a</span><span class="p">,</span> <span class="n">m1b</span><span class="p">,</span> <span class="n">s1b</span><span class="p">,</span> <span class="n">m2a</span><span class="p">,</span> <span class="n">s2a</span><span class="p">,</span> <span class="n">m2b</span><span class="p">,</span> <span class="n">s2b</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">iterobjs</span> <span class="p">:</span>  <span class="c1">#for each grid point gives all the data</span>

    <span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;Grid </span><span class="si">%r</span><span class="s2"> : </span><span class="si">%0.4f</span><span class="s2"> </span><span class="si">%0.04f</span><span class="s2"> </span><span class="si">%0.4f</span><span class="s2"> </span><span class="si">%0.04f</span><span class="s2"> </span><span class="si">%0.4f</span><span class="s2"> </span><span class="si">%0.04f</span><span class="s2"> </span><span class="si">%0.4f</span><span class="s2"> </span><span class="si">%0.04f</span><span class="s2">&quot;</span>
           <span class="o">%</span> <span class="p">(</span> <span class="n">params</span><span class="p">,</span> <span class="n">m1a</span><span class="p">,</span> <span class="n">s1a</span><span class="p">,</span> <span class="n">m1b</span><span class="p">,</span> <span class="n">s1b</span><span class="p">,</span> <span class="n">m2a</span><span class="p">,</span> <span class="n">s2a</span><span class="p">,</span> <span class="n">m2b</span><span class="p">,</span> <span class="n">s2b</span><span class="p">))</span>  
</pre></div>
</div>
</div>
</div>
<p>Uncomment the following cell to look into additional performance data stored in cv_result_.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#print(clf_DT_CV.cv_results_)</span>
</pre></div>
</div>
</div>
</div>
<p>It is important to understand that each model built through 10-fold cross-validation during hyperparameter optimization uses only 90% of the compounds in the training set and the remaining 10% is used for testing that model.  After all parameter value combinations are evaluated, the best parameter values are selected and used to rebuild a model from <strong>all</strong> compounds in the training set.  <strong>GridSearchCV()</strong> takes care of this last step automatically.  Therefore, there is no need to take an extra step to build a model using <strong>cls.fit()</strong> after hyperparameter optimization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply the model to predict the training compound&#39;s activity.</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">X_train</span> <span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate confusion matrix</span>
<span class="n">CMat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span>   
<span class="nb">print</span><span class="p">(</span><span class="n">CMat</span><span class="p">)</span>    <span class="c1"># [[TN, FP], </span>
               <span class="c1">#  [FN, TP]]</span>
<span class="c1"># Extracting TN, FP, FN, TP from the confusion matrix               </span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># True Negatives</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># False Positives</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># False Negatives</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># True Positives</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Negatives (TN):&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Positives (FP):&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Negatives (FN):&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Positives (TP):&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total predictions:&quot;</span><span class="p">,</span> <span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span> <span class="c1">#correct predictions/total predictions = (TP+TN)/(TP+TN+FP+FN)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># precision = TP / (TP + FP) measures how well model identifies actual positives</span>
<span class="n">sens</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>    <span class="c1"># sensitivity = TP / (FN + TP) measures how well model identifies actual positives</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># specificity = TN / (TN + FP)measures how well model identifies actual negatives</span>
<span class="n">bacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">sens</span> <span class="o">+</span> <span class="n">spec</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>    <span class="c1">#averages sensititivy and specificity</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">prec</span> <span class="o">*</span> <span class="n">sens</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec</span> <span class="o">+</span> <span class="n">sens</span><span class="p">)</span>  <span class="c1"># F1 score is the harmonic mean of precision and sensitivity</span>

<span class="n">y_score</span> <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span> <span class="n">X_train</span> <span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1">#returns proability of each class, [:, 1] extracts the probability of the positive class (label 1) for each sample.</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span> <span class="p">)</span> <span class="c1">#measures how well the model ranks psitive vs negative samples. AUC = 1.0 → perfect model; AUC = 0.5 → random guessing.</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set performance metrics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy          = </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># how accurate is the model overall</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision         = </span><span class="si">{</span><span class="n">prec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it identifies actual positives (precision)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity       = </span><span class="si">{</span><span class="n">sens</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it catches positives (sensitivity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Specificity       = </span><span class="si">{</span><span class="n">spec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it avoids false negatives (specificity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Balanced Accuracy = </span><span class="si">{</span><span class="n">bacc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How balanced its performance is across classes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score          = </span><span class="si">{</span><span class="n">f1_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># Harmonic mean of precision and sensitivity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC-ROC           = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1">#How well it ranks predictions (AUC)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Interpreting key metrics from the confusion matrix on training set</strong>
<p>Compare these performance data with those from section 8b. (for the training set only).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#-- Apply the model to predict the test set compounds&#39; activity.</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate confusion matrix</span>
<span class="n">CMat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span>   
<span class="nb">print</span><span class="p">(</span><span class="n">CMat</span><span class="p">)</span>    <span class="c1"># [[TN, FP], </span>
               <span class="c1">#  [FN, TP]]</span>
<span class="c1"># Extracting TN, FP, FN, TP from the confusion matrix               </span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># True Negatives</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># False Positives</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># False Negatives</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">CMat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># True Positives</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Negatives (TN):&quot;</span><span class="p">,</span> <span class="n">TN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Positives (FP):&quot;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;False Negatives (FN):&quot;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True Positives (TP):&quot;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total predictions:&quot;</span><span class="p">,</span> <span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="p">)</span> <span class="c1">#correct predictions/total predictions = (TP+TN)/(TP+TN+FP+FN)</span>
<span class="n">prec</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># precision = TP / (TP + FP) measures how well model identifies actual positives</span>
<span class="n">sens</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>    <span class="c1"># sensitivity = TP / (FN + TP) measures how well model identifies actual positives</span>
<span class="n">spec</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>    <span class="c1"># specificity = TN / (TN + FP)measures how well model identifies actual negatives</span>
<span class="n">bacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">sens</span> <span class="o">+</span> <span class="n">spec</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>    <span class="c1">#averages sensititivy and specificity</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">prec</span> <span class="o">*</span> <span class="n">sens</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec</span> <span class="o">+</span> <span class="n">sens</span><span class="p">)</span>  <span class="c1"># F1 score is the harmonic mean of precision and sensitivity</span>

<span class="n">y_score</span> <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span> <span class="n">X_test</span> <span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1">#returns proability of each class, [:, 1] extracts the probability of the positive class (label 1) for each sample.</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span> <span class="p">)</span> <span class="c1">#measures how well the model ranks psitive vs negative samples. AUC = 1.0 → perfect model; AUC = 0.5 → random guessing.</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set performance metrics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy          = </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># how accurate is the model overall</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision         = </span><span class="si">{</span><span class="n">prec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it identifies actual positives (precision)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity       = </span><span class="si">{</span><span class="n">sens</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it catches positives (sensitivity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Specificity       = </span><span class="si">{</span><span class="n">spec</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How well it avoids false negatives (specificity)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Balanced Accuracy = </span><span class="si">{</span><span class="n">bacc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># How balanced its performance is across classes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score          = </span><span class="si">{</span><span class="n">f1_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># Harmonic mean of precision and sensitivity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AUC-ROC           = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1">#How well it ranks predictions (AUC)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Interpreting key metrics from the confusion matrix on test set</strong>
<p>Compare these performance data with those from section 8b. (for the test set only).</p>
<p>Let’s use the new cross-validated decision tree model to predict the same molecules we had used before.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Define new SMILES string</span>
<span class="n">new_smiles</span> <span class="o">=</span> <span class="s2">&quot;CC(=O)OC1=CC=CC=C1C(=O)O&quot;</span> <span class="c1"># CID 2242 aspirin should be INactive</span>
<span class="c1">#new_smiles = &quot;C1=CC=C(C=C1)C(C2=CC=CC=C2)(C3=CC=CC=C3Cl)N4C=CN=C4&quot; # CID = 2812 should be active</span>
<span class="c1">#new_smiles = &quot;C1=CC=C(C(=C1)C2=NC(=NO2)C3=CC=NC=C3)Cl&quot; #CID 65758 should be active</span>
<span class="c1">#new_smiles = &quot;C1=CC(=CC=C1C2=COC3=CC(=CC(=C3C2=O)O)O)O&quot; #CID 5280961 should be active</span>
<span class="c1">#new_smiles = &quot;CN(C1CCN(CC1)C2=NC3=CC=CC=C3N2CC4=CC=C(C=C4)F)C5=NC=CC(=O)N5&quot; #CID 65906 should be INactive</span>
<span class="c1">#new_smiles = &quot;C1=CNC(=O)NC1=O&quot; #CID 1174 should be INactive</span>
<span class="c1">#new_smiles = &quot;CCCCCC1=CC(=C2C=CC(OC2=C1)(C)CCC=C(C)C)O&quot; #CID30219 not in datbase (CBC)</span>
<span class="c1">#new_smiles = &quot;C[C@H]1C[C@@H](C(=O)[C@@H](C1)[C@@H](CC2CC(=O)NC(=O)C2)O)C&quot; #CID 6197 should be active</span>
<span class="c1">#new_smiles = &quot;CCCCCC1=CC(=C2[C@@H]3C=C(CC[C@H]3C(OC2=C1)(C)C)C)O&quot; #CID16078 in database and should be active (THC)</span>
<span class="c1">#new_smiles = &quot;COC1=CC(=CC(=C1OC)OC)CCN&quot; #CID4076 not in database (mescaline)</span>
<span class="c1">#new_smiles = &quot;CC1=C(C(CCC1)(C)C)/C=C/C(=C/C=C/C(=C/CO)/C)/C&quot; # vitamin A not in database</span>
<span class="n">mol</span> <span class="o">=</span> <span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">new_smiles</span><span class="p">)</span>
<span class="n">mol</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">rdkit.DataStructs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConvertToNumpyArray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">fp</span> <span class="o">=</span> <span class="n">MACCSkeys</span><span class="o">.</span><span class="n">GenMACCSKeys</span><span class="p">(</span><span class="n">mol</span><span class="p">)</span>
<span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span> 
<span class="n">ConvertToNumpyArray</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="n">arr</span><span class="p">)</span>
<span class="n">arr_filtered</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf_DT_CV</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">arr_filtered</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-warning">
<strong>Comparing Naive Bayes and Cross Validated Decision Tree Models</strong>
<p>How do these to models compare in their accuracy and AUC-ROC? Is one particularly better than the other in the test set data?</p>
<div class="alert alert-block alert-success">
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="homework">
<h1><center>Homework</center><a class="headerlink" href="#homework" title="Link to this heading">#</a></h1>
<p>There are three parts to this homework assignment:</p>
<ol class="arabic simple">
<li><p>Generate a new model with Random Forest and ECFP4 equivalent descriptors.</p></li>
<li><p>Compare models</p></li>
<li><p>Journal article review</p></li>
</ol>
<div class="alert alert-block alert-success">
<section id="part-1-random-forest-with-ecfp4-descriptors">
<h2>Part 1: Random Forest with ECFP4 descriptors<a class="headerlink" href="#part-1-random-forest-with-ecfp4-descriptors" title="Link to this heading">#</a></h2>
<p>In this assignment, we will build predictive models using the same aromatase data. However, you will use a random forest classifier and ECFP4 as descriptors.</p>
<p><strong>step 1</strong> Show the following information to make sure that the activity data in the <strong>df_activity</strong> data frame is still available.</p>
<ul class="simple">
<li><p>The first five lines of <strong>df_activity</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_activity</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The counts of active/inactive compounds in <strong>df_activity</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_activity</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;activity&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 2</strong> Show the following information to make sure the structure data is still available.</p>
<ul class="simple">
<li><p>The first five lines of <strong>df_smiles</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_smiles</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>the number of rows of <strong>df_smiles</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">df_smiles</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 3</strong> Generate the (ECFP-equivalent) circular fingerprints from the SMILES strings.</p>
<ul class="simple">
<li><p>Use RDKit to generate 1024-bit-long circular fingerprints.</p></li>
<li><p>Set the radius of the circular fingerprint to 2.</p></li>
<li><p>Store the fingerprints in a data_frame called <strong>df_fps2</strong> (along with the CIDs).</p></li>
<li><p>Print the dimension of <strong>df_fps2</strong>.</p></li>
<li><p>Show the first five lines of <strong>df_fps2</strong>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># write your code here</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 4</strong> Merge the <strong>df_activity</strong> and <strong>df_fps2</strong> data frames into a data frame called <strong>df_data2</strong></p>
<ul class="simple">
<li><p>Join the two data frames using the CID column as keys.</p></li>
<li><p>Remove the rows that have any NULL values (i.e., compounds for which the fingerprints couldn’t be generated).</p></li>
<li><p>Print the dimension of <strong>df_data2</strong>.</p></li>
<li><p>Show the first five lines of <strong>df_data2</strong>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># write your code here</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 5</strong> Prepare input and output data for model building</p>
<ul class="simple">
<li><p>Load the fingerprint data into 2-D array (X) and the activity data into 1-D array (y).</p></li>
<li><p>Show the dimension of X and y.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># write your code here</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Remove zero-variance features from X (if any).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># write your code here</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Split the data set into training and test sets (90% vs 10%) (using random_state=3100).</p></li>
<li><p>Print the dimension of X and y for the training and test sets.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your code in this cell.</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Balance the training data set through downsampling.</p></li>
<li><p>Show the number of inactive/active compounds in the downsampled training set.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># write your code here</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 6</strong> Building a Random Forest model using the balanced training data set.</p>
<ul class="simple">
<li><p>First read the followng documents about random forest (https://scikit-learn.org/stable/modules/ensemble.html#forest and https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier).</p></li>
<li><p>Use 10-fold cross validation to select the best value for the “n_estimators” parameter that maximizes the <strong>balanced accuracy</strong>.  Test 40 values from 5 to 200 with an increment of 5 (e.g., 5, 10, 15, 20, …, 190, 195, 200).</p></li>
<li><p>For parameters ‘max_depth’, ‘min_samples_leaf’, and ‘min_samples_split’, use the best values found in Section 9.</p></li>
<li><p>For other parameters, use the default values.</p></li>
<li><p>For each parameter value, print the mean balanced accuracies (for both training and test from cross validation).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># write your code here</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 7</strong> Apply the developed RF model to predict the activity of the <strong>training</strong> set compounds.</p>
<ul class="simple">
<li><p>Report the confusion matrix.</p></li>
<li><p>Report the accuracy, balanced accuracy, sensitivity, specificity, and auc-roc.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># write your code here</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 8</strong> Apply the developed RF model to predict the activity of the <strong>test</strong> set compounds.</p>
<ul class="simple">
<li><p>Report the accuracy, balanced accurayc, sensitivity, specificity, and auc-roc.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># write your code here</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 9</strong> Test this model on your previous selected molecules</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Define new SMILES string</span>
<span class="n">new_smiles</span> <span class="o">=</span> <span class="s2">&quot;CC(=O)OC1=CC=CC=C1C(=O)O&quot;</span> <span class="c1"># CID 2242 aspirin should be INactive</span>
<span class="c1">#new_smiles = &quot;C1=CC=C(C=C1)C(C2=CC=CC=C2)(C3=CC=CC=C3Cl)N4C=CN=C4&quot; # CID = 2812 should be active</span>
<span class="c1">#new_smiles = &quot;C1=CC=C(C(=C1)C2=NC(=NO2)C3=CC=NC=C3)Cl&quot; #CID 65758 should be active</span>
<span class="c1">#new_smiles = &quot;C1=CC(=CC=C1C2=COC3=CC(=CC(=C3C2=O)O)O)O&quot; #CID 5280961 should be active</span>
<span class="c1">#new_smiles = &quot;CN(C1CCN(CC1)C2=NC3=CC=CC=C3N2CC4=CC=C(C=C4)F)C5=NC=CC(=O)N5&quot; #CID 65906 should be INactive</span>
<span class="c1">#new_smiles = &quot;C1=CNC(=O)NC1=O&quot; #CID 1174 should be INactive</span>
<span class="c1">#new_smiles = &quot;CCCCCC1=CC(=C2C=CC(OC2=C1)(C)CCC=C(C)C)O&quot; #CID30219 not in datbase (CBC)</span>
<span class="c1">#new_smiles = &quot;C[C@H]1C[C@@H](C(=O)[C@@H](C1)[C@@H](CC2CC(=O)NC(=O)C2)O)C&quot; #CID 6197 should be active</span>
<span class="c1">#new_smiles = &quot;CCCCCC1=CC(=C2[C@@H]3C=C(CC[C@H]3C(OC2=C1)(C)C)C)O&quot; #CID16078 in database and should be active (THC)</span>
<span class="c1">#new_smiles = &quot;COC1=CC(=CC(=C1OC)OC)CCN&quot; #CID4076 not in database (mescaline)</span>
<span class="c1">#new_smiles = &quot;CC1=C(C(CCC1)(C)C)/C=C/C(=C/C=C/C(=C/CO)/C)/C&quot; # vitamin A not in database</span>
<span class="n">mol</span> <span class="o">=</span> <span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">new_smiles</span><span class="p">)</span>
<span class="n">mol</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># write your code here</span>
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-success">
</section>
<section id="part-2-model-comparison-and-prediction-evaluation">
<h2>Part 2: Model Comparison and Prediction Evaluation<a class="headerlink" href="#part-2-model-comparison-and-prediction-evaluation" title="Link to this heading">#</a></h2>
<p>You have now trained and evaluated three different classification models on aromatase inhibitor data:</p>
<ul class="simple">
<li><p>Naive Bayes and Decision Tree using MACCS Keys</p></li>
<li><p>Random Forest using ECFP4 fingerprints</p></li>
</ul>
<p>Instructions:</p>
<ol class="arabic simple">
<li><p>Create a summary table in Excel that includes the following for each model: (I will provide the Excel template)</p></li>
</ol>
<ul class="simple">
<li><p>Overall performance metrics (e.g., accuracy, balanced accuracy, ROC-AUC, F1-score)</p></li>
<li><p>Any notes on overfitting or class imbalance (e.g., large train/test gaps)</p></li>
<li><p>Strengths or weaknesses you observed based on the model type or feature set</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Evaluate predictions for individual molecules:</p></li>
</ol>
<ul class="simple">
<li><p>Include a row for each test set molecule (or selected examples).</p></li>
<li><p>For each molecule, note the predicted activity (active/inactive) from each model.</p></li>
<li><p>Highlight any molecules where different models gave different predictions.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Reflection:</p></li>
</ol>
<ul class="simple">
<li><p>Did any of your molecules outside the original dataset (e.g., ones you added) receive different predictions depending on the model?</p></li>
<li><p>Which model do you trust most for these borderline cases, and why?</p></li>
</ul>
<div class="alert alert-block alert-success">
</section>
<section id="part-3">
<h2>Part 3<a class="headerlink" href="#part-3" title="Link to this heading">#</a></h2>
<p>Read the following two papers (You may need to request them via interlibrary loan.)</p>
<ul class="simple">
<li><p>Paper 1: <em>Chem. Res. Toxicol.</em> (https://doi.org/10.1021/acs.chemrestox.7b00037)</p></li>
<li><p>Paper 2: <em>Environmental Science &amp; Technology</em> (https://doi.org/10.1021/acs.est.0c05771)</p></li>
</ul>
<p>Answer the following questions (in no more than five sentences for each question).</p>
<ul class="simple">
<li><p>What different approaches did the <em>Chem. Res. Toxicol.</em> paper take to develop prediction models (how do they compare to those used in this notebook)?</p></li>
<li><p>How different are the models reported in the <em>Chem. Res. Toxicol.</em> paper from those constructed in the <em>Environmental Science &amp; Technology</em> paper (in terms of the performance measures)?</p></li>
<li><p>What would you do to develop models with improved performance?</p></li>
<li><p>How could you use the molecular similarity notebook you developed in this course to find and test other likely active molecules at P450 19A1?</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="acknowledgments">
<h1>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Link to this heading">#</a></h1>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "datachem"
        },
        kernelOptions: {
            name: "datachem",
            path: "./content/modules/10-Machine-Learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'datachem'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="README.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Module 10: Supervised ML</p>
      </div>
    </a>
    <a class="right-next"
       href="../../appendices/README.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Appendices</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Machine Learning Basics</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-obtaining-and-cleaning-data">Part 1: Obtaining and Cleaning Data</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-bioactivity-data-from-pubchem">1. Import bioactivity data from PubChem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-the-number-of-compounds-for-each-activity-group">2. Check the number of compounds for each activity group</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#select-active-inactive-compounds-for-model-building">3. Select active/inactive compounds for model building</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-drop-substances-without-associated-cids">3a. Drop substances without associated CIDs.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-remove-cids-with-conflicting-activities">3b. Remove CIDs with conflicting activities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-remove-redundant-data">3c. Remove redundant data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-adding-numeric-activity-classes">3d. Adding “numeric” activity classes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#e-create-a-smaller-data-frame-that-only-contains-cids-and-activities">3e. Create a smaller data frame that only contains CIDs and activities.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#download-structure-information-for-each-compound-from-pubchem">4. Download structure information for each compound from PubChem</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-convert-smiles-to-binary-data-for-model-input">Part 2: Convert SMILES to Binary Data for Model Input</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-maccs-keys-from-smiles">5. Generate MACCS keys from SMILES.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#merge-activity-data-and-fingerprint-information">6. Merge activity data and fingerprint information</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-machine-learning">Part 3: Machine Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparation-for-model-building">7. Preparation for model building</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-loading-the-data-into-x-and-y">7a. Loading the data into X and y.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-remove-zero-variance-features">7b. Remove zero-variance features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-train-test-split-a-9-1-ratio">7c. Train-Test-Split (a 9:1 ratio)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-balancing-the-training-set">7d. Balancing the training set</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#downsampling">Downsampling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-a-model-using-the-training-set">8. Build a model using the training set.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-naive-bayes">8a. Naïve Bayes</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-decision-tree">8b Decision Tree</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-building-through-cross-validation">9. Model building through cross-validation</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#homework"><center>Homework</center></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-random-forest-with-ecfp4-descriptors">Part 1: Random Forest with ECFP4 descriptors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-model-comparison-and-prediction-evaluation">Part 2: Model Comparison and Prediction Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3">Part 3</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#acknowledgments">Acknowledgments</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert Belford
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>